# Release Observability & Monitoring Infrastructure

**Version**: 1.0
**Last Updated**: 2026-01-08
**Owner**: Engineering Lead + SRE Lead
**Status**: Active

---

## Document Purpose

This document defines the comprehensive observability and monitoring infrastructure for the v1.1.0-beta release. It establishes logging strategy, distributed tracing, metrics collection, alerting systems, and debugging tools that provide visibility into caro's runtime behavior while respecting user privacy and maintaining minimal performance overhead.

**Audience**: Engineering Lead, SRE Lead, On-Call Engineers, Contributors

**Related Documents**:
- `v1.1.0-release-metrics-dashboard-monitoring.md` - Dashboard and metrics strategy
- `v1.1.0-security-privacy-compliance-framework.md` - Privacy constraints
- `v1.1.0-performance-optimization-benchmarking.md` - Performance requirements
- `v1.1.0-crisis-management-emergency-response.md` - Incident response

---

## Table of Contents

1. [Observability Philosophy](#observability-philosophy)
2. [Logging Strategy](#logging-strategy)
3. [Distributed Tracing](#distributed-tracing)
4. [Metrics Collection](#metrics-collection)
5. [Error Tracking](#error-tracking)
6. [Performance Profiling](#performance-profiling)
7. [Debugging Tools](#debugging-tools)
8. [Privacy & Compliance](#privacy--compliance)
9. [Local Development](#local-development)

---

## Observability Philosophy

### Core Principles

**1. Privacy First**
- No PII collection (no raw user queries, no file paths, no system info)
- Opt-in telemetry (default OFF)
- Local-only logs (never sent to external services)
- Users can inspect and delete all telemetry data

**2. Zero Performance Impact in Production**
- Logging overhead <1% CPU
- Structured logging (no string formatting in hot paths)
- Async log writes (non-blocking)
- Sampling for high-volume events

**3. Actionable Insights**
- Every log/metric should answer: "What action should I take?"
- Focus on user-facing issues (not internal implementation details)
- Context-rich errors (include environment, backend, platform)

**4. Developer-Friendly**
- Easy to enable verbose logging: `RUST_LOG=debug caro ...`
- Human-readable output (structured JSON + pretty-print option)
- Integration with standard tools (grep, jq, etc.)

**5. Production-Ready from Day 1**
- Built-in observability (not bolted on later)
- Graceful degradation (logging failure doesn't crash app)
- Self-monitoring (observe the observer)

---

## Logging Strategy

### Log Levels & Usage

| Level | When to Use | Examples | Volume |
|-------|-------------|----------|--------|
| **ERROR** | Unrecoverable errors, user-visible failures | Backend timeout, parse error, file not found | <1/min |
| **WARN** | Recoverable issues, degraded functionality | Slow query (>1s), fallback to static matcher, deprecated config | <10/min |
| **INFO** | Normal operations, state changes | Backend selected, command generated, safety validation passed | <100/min |
| **DEBUG** | Detailed execution flow, internal state | Prompt construction, regex matching, token counts | <1000/min |
| **TRACE** | Extremely verbose, every function entry/exit | HTTP request/response bodies, full AST dumps | <10000/min |

---

### Structured Logging Format

**Library**: `tracing` (Rust industry standard)

**Why `tracing` over `log`?**
- Structured (key-value pairs, not string formatting)
- Async-aware (integrates with tokio)
- Spans (distributed tracing)
- Performance (lazy evaluation)

**Example: Structured Log Entry**
```rust
use tracing::{info, instrument};

#[instrument(skip(backend))]
pub async fn generate_command(
    query: &str,
    backend: &dyn InferenceBackend,
) -> Result<CommandResult> {
    info!(
        backend = %backend.name(),
        query_length = query.len(),
        "generating command"
    );

    let start = Instant::now();
    let result = backend.generate(query).await?;
    let elapsed = start.elapsed();

    info!(
        backend = %backend.name(),
        command = %result.command,
        confidence = result.confidence,
        latency_ms = elapsed.as_millis(),
        "command generated successfully"
    );

    Ok(result)
}
```

**Output (JSON format for production)**:
```json
{
  "timestamp": "2026-01-15T14:32:15.123Z",
  "level": "INFO",
  "target": "caro::agent",
  "span": {
    "name": "generate_command",
    "backend": "embedded"
  },
  "fields": {
    "backend": "embedded",
    "query_length": 42,
    "message": "generating command"
  }
}

{
  "timestamp": "2026-01-15T14:32:15.456Z",
  "level": "INFO",
  "target": "caro::agent",
  "span": {
    "name": "generate_command",
    "backend": "embedded"
  },
  "fields": {
    "backend": "embedded",
    "command": "find . -type f -mtime -1",
    "confidence": 0.92,
    "latency_ms": 333,
    "message": "command generated successfully"
  }
}
```

**Output (Human-readable format for development)**:
```
2026-01-15 14:32:15.123 INFO caro::agent: generating command
    backend: embedded
    query_length: 42

2026-01-15 14:32:15.456 INFO caro::agent: command generated successfully
    backend: embedded
    command: find . -type f -mtime -1
    confidence: 0.92
    latency_ms: 333
```

---

### Log Configuration

**Environment Variables:**
```bash
# Log level (default: INFO)
RUST_LOG=caro=debug,tokio=info,hyper=warn

# Log format (default: human-readable)
CARO_LOG_FORMAT=json  # or "pretty"

# Log output (default: stderr)
CARO_LOG_FILE=/var/log/caro.log

# Disable all logging (performance mode)
CARO_LOG=off
```

**Code: Log Subscriber Initialization**
```rust
use tracing_subscriber::{fmt, EnvFilter, layer::SubscriberExt, util::SubscriberInitExt};

pub fn init_logging() -> Result<()> {
    let format = env::var("CARO_LOG_FORMAT").unwrap_or_else(|_| "pretty".to_string());
    let filter = EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| EnvFilter::new("caro=info"));

    let subscriber = tracing_subscriber::registry()
        .with(filter);

    match format.as_str() {
        "json" => {
            let json_layer = fmt::layer()
                .json()
                .with_current_span(true)
                .with_span_list(true);
            subscriber.with(json_layer).init();
        }
        "pretty" => {
            let pretty_layer = fmt::layer()
                .pretty()
                .with_file(true)
                .with_line_number(true)
                .with_thread_ids(true);
            subscriber.with(pretty_layer).init();
        }
        _ => {
            return Err(anyhow!("Invalid log format: {}", format));
        }
    }

    Ok(())
}
```

---

### Privacy-Safe Logging

**NEVER Log**:
❌ Raw user queries: `query: "find my bank statements"`
❌ File paths: `/Users/alice/Documents/passwords.txt`
❌ System info: hostname, username, IP address
❌ Generated commands containing sensitive data

**DO Log**:
✅ Query length: `query_length: 42`
✅ Intent category: `intent: FILE_SEARCH`
✅ Backend used: `backend: embedded`
✅ Performance metrics: `latency_ms: 333`
✅ Error types: `error: BackendTimeout`
✅ Anonymized patterns: `pattern: file_search_by_date`

**Example: Privacy-Safe Logging**
```rust
// ❌ BAD: Logs PII
info!("User query: {}", query);

// ✅ GOOD: Logs metadata only
info!(
    query_length = query.len(),
    intent = classify_intent(query),
    "processing query"
);

// ❌ BAD: Logs file path
warn!("Config file not found: {}", path);

// ✅ GOOD: Logs error type only
warn!(
    error = "config_not_found",
    "using default configuration"
);
```

---

## Distributed Tracing

### What is Distributed Tracing?

Distributed tracing tracks a single request as it flows through multiple components:

```
User Query → Agent → Backend Selection → Prompt Builder → LLM Inference → Safety Validation → Response
    |          |            |                   |                |                  |             |
    └──────────┴────────────┴───────────────────┴────────────────┴──────────────────┴─────────────┘
                                    Single Trace (with spans)
```

Each component creates a "span" with timing, metadata, and parent/child relationships.

---

### Tracing Implementation (Rust `tracing` crate)

**Code: Instrument Functions with Spans**
```rust
use tracing::{instrument, info, warn};

#[instrument(skip(self))]
pub async fn process_query(&self, query: &str) -> Result<CommandResult> {
    info!("starting query processing");

    // Child span: Select backend
    let backend = self.select_backend(query).await?;

    // Child span: Generate command
    let result = self.generate_command(query, backend).await?;

    // Child span: Validate safety
    let validation = self.validate_safety(&result.command).await?;

    if validation.is_safe {
        info!("query processed successfully");
        Ok(result)
    } else {
        warn!("unsafe command blocked");
        Err(anyhow!("Command blocked by safety validation"))
    }
}

#[instrument(skip(self))]
async fn select_backend(&self, query: &str) -> Result<&dyn InferenceBackend> {
    // Backend selection logic
}

#[instrument(skip(self, backend))]
async fn generate_command(
    &self,
    query: &str,
    backend: &dyn InferenceBackend,
) -> Result<CommandResult> {
    // Command generation logic
}

#[instrument(skip(self))]
async fn validate_safety(&self, command: &str) -> Result<SafetyResult> {
    // Safety validation logic
}
```

**Trace Output (Hierarchical Spans)**:
```
TRACE caro::agent: process_query [2.5s]
  ├─ TRACE caro::agent: select_backend [0.1s]
  │   └─ INFO: selected backend: embedded
  ├─ TRACE caro::agent: generate_command [2.2s]
  │   ├─ TRACE caro::backends::embedded: load_model [1.8s]
  │   ├─ TRACE caro::backends::embedded: tokenize [0.1s]
  │   ├─ TRACE caro::backends::embedded: inference [0.2s]
  │   └─ TRACE caro::backends::embedded: decode [0.1s]
  └─ TRACE caro::agent: validate_safety [0.2s]
      ├─ TRACE caro::safety: check_destructive_patterns [0.1s]
      └─ TRACE caro::safety: check_privilege_escalation [0.1s]
```

**Insights from Traces**:
- Total latency: 2.5s
- Bottleneck: `load_model` (1.8s) → Optimization target
- Spans with errors are highlighted
- Parent/child relationships show execution flow

---

### Trace Sampling (Production)

**Problem**: Tracing every request is expensive (storage, CPU)

**Solution**: Sample traces based on criteria

```rust
use tracing_subscriber::layer::SubscriberExt;
use tracing_subscriber::EnvFilter;

pub fn init_tracing() {
    let filter = EnvFilter::new("caro=trace")
        .add_directive("tokio=info".parse().unwrap());

    // Sample 10% of requests
    let sampler = TraceIdRatioBasedSampler::new(0.1);

    tracing_subscriber::registry()
        .with(filter)
        .with(sampler)
        .init();
}
```

**Sampling Strategies**:
- **Always sample**: Errors (100%)
- **High rate**: Slow requests >1s (100%)
- **Medium rate**: First 1000 requests per day per user (to detect onboarding issues)
- **Low rate**: Normal requests (10%)

---

## Metrics Collection

### Metrics Types

**1. Counters** (monotonically increasing)
- Total commands generated
- Total errors
- Total safety blocks

**2. Gauges** (point-in-time values)
- Active users (in last 7 days)
- Memory usage (MB)
- Open file descriptors

**3. Histograms** (distribution)
- Command generation latency (p50, p95, p99)
- Query length distribution
- Confidence score distribution

---

### Metrics Implementation (Prometheus Format)

**Library**: `prometheus` crate (industry standard)

**Code: Define Metrics**
```rust
use prometheus::{Counter, Histogram, IntGauge, Registry};
use once_cell::sync::Lazy;

pub static METRICS: Lazy<Metrics> = Lazy::new(Metrics::new);

pub struct Metrics {
    pub commands_generated: Counter,
    pub commands_failed: Counter,
    pub safety_blocks: Counter,
    pub backend_latency: Histogram,
    pub active_users: IntGauge,
}

impl Metrics {
    pub fn new() -> Self {
        let commands_generated = Counter::new(
            "caro_commands_generated_total",
            "Total commands generated"
        ).unwrap();

        let commands_failed = Counter::new(
            "caro_commands_failed_total",
            "Total commands that failed to generate"
        ).unwrap();

        let safety_blocks = Counter::new(
            "caro_safety_blocks_total",
            "Total commands blocked by safety validation"
        ).unwrap();

        let backend_latency = Histogram::with_opts(
            prometheus::HistogramOpts::new(
                "caro_backend_latency_seconds",
                "Backend command generation latency"
            )
            .buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0])
        ).unwrap();

        let active_users = IntGauge::new(
            "caro_active_users",
            "Number of active users (7-day window)"
        ).unwrap();

        Self {
            commands_generated,
            commands_failed,
            safety_blocks,
            backend_latency,
            active_users,
        }
    }

    pub fn register(&self, registry: &Registry) -> Result<()> {
        registry.register(Box::new(self.commands_generated.clone()))?;
        registry.register(Box::new(self.commands_failed.clone()))?;
        registry.register(Box::new(self.safety_blocks.clone()))?;
        registry.register(Box::new(self.backend_latency.clone()))?;
        registry.register(Box::new(self.active_users.clone()))?;
        Ok(())
    }
}
```

**Code: Record Metrics**
```rust
use crate::metrics::METRICS;

pub async fn generate_command(&self, query: &str) -> Result<CommandResult> {
    let start = Instant::now();

    match self.backend.generate(query).await {
        Ok(result) => {
            // Record success
            METRICS.commands_generated.inc();
            METRICS.backend_latency.observe(start.elapsed().as_secs_f64());
            Ok(result)
        }
        Err(e) => {
            // Record failure
            METRICS.commands_failed.inc();
            Err(e)
        }
    }
}

pub fn validate_safety(&self, command: &str) -> SafetyResult {
    let result = self.validator.validate(command);

    if result.blocked {
        METRICS.safety_blocks.inc();
    }

    result
}
```

---

### Metrics Export (Prometheus Endpoint)

**Optional: HTTP Endpoint for Metrics Scraping**

```rust
use prometheus::{Encoder, TextEncoder};
use warp::Filter;

#[tokio::main]
async fn main() {
    // Start metrics HTTP server (optional, for advanced users)
    if env::var("CARO_METRICS_ENABLED").is_ok() {
        tokio::spawn(async {
            let metrics_route = warp::path!("metrics")
                .map(|| {
                    let encoder = TextEncoder::new();
                    let metric_families = prometheus::gather();
                    let mut buffer = Vec::new();
                    encoder.encode(&metric_families, &mut buffer).unwrap();
                    String::from_utf8(buffer).unwrap()
                });

            warp::serve(metrics_route)
                .run(([127, 0, 0, 1], 9090))
                .await;
        });
    }

    // Main application logic
    // ...
}
```

**Access Metrics**:
```bash
# Enable metrics server
export CARO_METRICS_ENABLED=1

# Run caro
caro "list files"

# Scrape metrics (in another terminal)
curl http://localhost:9090/metrics

# Output:
# caro_commands_generated_total 1
# caro_commands_failed_total 0
# caro_safety_blocks_total 0
# caro_backend_latency_seconds_bucket{le="0.5"} 1
# caro_backend_latency_seconds_sum 0.333
# caro_backend_latency_seconds_count 1
```

---

### Local Metrics Storage (Privacy-Preserving)

**Alternative to HTTP Endpoint: SQLite Database**

```rust
use rusqlite::{Connection, Result};

pub struct LocalMetrics {
    conn: Connection,
}

impl LocalMetrics {
    pub fn new() -> Result<Self> {
        let path = dirs::cache_dir()
            .unwrap()
            .join("caro")
            .join("metrics.db");

        let conn = Connection::open(path)?;

        conn.execute(
            "CREATE TABLE IF NOT EXISTS events (
                id INTEGER PRIMARY KEY,
                timestamp INTEGER NOT NULL,
                event_type TEXT NOT NULL,
                backend TEXT,
                latency_ms INTEGER,
                success BOOLEAN
            )",
            [],
        )?;

        Ok(Self { conn })
    }

    pub fn record_command(&self, backend: &str, latency: Duration, success: bool) -> Result<()> {
        self.conn.execute(
            "INSERT INTO events (timestamp, event_type, backend, latency_ms, success)
             VALUES (?1, ?2, ?3, ?4, ?5)",
            [
                chrono::Utc::now().timestamp(),
                "command_generated",
                backend,
                latency.as_millis() as i64,
                if success { 1 } else { 0 },
            ],
        )?;

        Ok(())
    }

    pub fn get_stats(&self, days: i64) -> Result<Stats> {
        let cutoff = chrono::Utc::now().timestamp() - (days * 86400);

        let total: i64 = self.conn.query_row(
            "SELECT COUNT(*) FROM events WHERE timestamp > ?1",
            [cutoff],
            |row| row.get(0),
        )?;

        let success: i64 = self.conn.query_row(
            "SELECT COUNT(*) FROM events WHERE timestamp > ?1 AND success = 1",
            [cutoff],
            |row| row.get(0),
        )?;

        Ok(Stats {
            total_commands: total as usize,
            successful_commands: success as usize,
            success_rate: (success as f64) / (total as f64),
        })
    }
}
```

**Benefits**:
- Local-only (no data leaves user's machine)
- Users can inspect: `sqlite3 ~/.cache/caro/metrics.db`
- Users can delete: `rm ~/.cache/caro/metrics.db`
- Respects privacy (no PII stored)

---

## Error Tracking

### Error Categories

| Category | Severity | User Action | Example |
|----------|----------|-------------|---------|
| **User Error** | Low | Fix input | Invalid query, file not found |
| **Configuration Error** | Medium | Fix config | Invalid backend URL, missing API key |
| **Backend Error** | High | Retry or switch backend | Timeout, connection refused, OOM |
| **Bug** | Critical | Report to team | Panic, assertion failure, logic error |

---

### Error Context Enrichment

**Code: Add Context to Errors**
```rust
use anyhow::{Context, Result};

pub async fn generate_command(&self, query: &str) -> Result<CommandResult> {
    let backend = self.select_backend(query)
        .context("Failed to select backend")?;

    let result = backend.generate(query)
        .await
        .context(format!("Backend '{}' failed to generate command", backend.name()))?;

    Ok(result)
}
```

**Error Output (with context chain)**:
```
Error: Backend 'embedded' failed to generate command

Caused by:
    0: Model inference failed
    1: Out of memory: Failed to allocate 1GB tensor
```

---

### Automatic Error Reporting (Opt-In)

**Sentry Integration (Future: v1.2.0)**
```rust
#[cfg(feature = "sentry")]
fn init_sentry() {
    let _guard = sentry::init((
        env::var("SENTRY_DSN").unwrap(),
        sentry::ClientOptions {
            release: Some(env!("CARGO_PKG_VERSION").into()),
            environment: Some("production".into()),
            ..Default::default()
        },
    ));
}

// Automatic error capture
pub fn run_app() -> Result<()> {
    let result = do_work();

    #[cfg(feature = "sentry")]
    if let Err(ref e) = result {
        sentry::capture_error(e);
    }

    result
}
```

**Privacy Considerations**:
- Opt-in only (user must enable: `caro config set sentry.enabled true`)
- Scrub PII before sending (no queries, file paths, etc.)
- Users can review events before submission

---

## Performance Profiling

### Built-In Profiling Tools

**1. Flamegraph (CPU Profiling)**

```bash
# Install cargo-flamegraph
cargo install flamegraph

# Profile caro
cargo flamegraph --bin caro -- "list files"

# Open flamegraph.svg in browser
open flamegraph.svg
```

**Interpretation**:
- Wide boxes = CPU hotspots
- Identify: regex compilation, model loading, tokenization

---

**2. Heaptrack (Memory Profiling)**

```bash
# Install heaptrack
# Ubuntu: sudo apt install heaptrack
# macOS: brew install heaptrack

# Profile memory
heaptrack caro "list files"

# Analyze
heaptrack_gui heaptrack.caro.*.gz
```

**Insights**:
- Memory allocations by function
- Leaks (memory not freed)

---

**3. Tracing Spans (Latency Profiling)**

```bash
# Enable trace-level logging
RUST_LOG=caro=trace caro "list files"

# Output includes timing for each span
TRACE caro::agent: generate_command [2.5s]
  ├─ TRACE caro::backends::embedded: load_model [1.8s]  ← SLOW
  ├─ TRACE caro::backends::embedded: tokenize [0.1s]
  ├─ TRACE caro::backends::embedded: inference [0.2s]
  └─ TRACE caro::backends::embedded: decode [0.1s]
```

---

### Performance Benchmarks (Criterion.rs)

**Code: Benchmark Critical Paths**
```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_static_matcher(c: &mut Criterion) {
    let matcher = StaticMatcher::new();

    c.bench_function("static_matcher_simple", |b| {
        b.iter(|| {
            matcher.match_query(black_box("list files"))
        });
    });

    c.bench_function("static_matcher_complex", |b| {
        b.iter(|| {
            matcher.match_query(black_box("find files modified in the last 3 days larger than 1GB"))
        });
    });
}

criterion_group!(benches, bench_static_matcher);
criterion_main!(benches);
```

**Run Benchmarks**:
```bash
cargo bench

# Output:
static_matcher_simple   time: [42.3 µs 43.1 µs 44.0 µs]
static_matcher_complex  time: [67.8 µs 69.2 µs 70.8 µs]
```

---

## Debugging Tools

### 1. Verbose Mode (`--verbose` flag)

```rust
pub fn run_with_verbosity(query: &str, verbose: bool) -> Result<()> {
    if verbose {
        println!("Debug Info:");
        println!("  Query: {}", query);
        println!("  Query Length: {}", query.len());
        println!("  Platform: {}", Platform::detect());
        println!("  Backend: {}", backend.name());
        println!();
    }

    let result = generate_command(query)?;

    if verbose {
        println!("Generated Command:");
        println!("  {}", result.command);
        println!("  Confidence: {:.2}", result.confidence);
        println!("  Latency: {}ms", result.latency.as_millis());
    }

    Ok(())
}
```

**Usage**:
```bash
caro --verbose "list files"

# Output:
Debug Info:
  Query: list files
  Query Length: 10
  Platform: macOS
  Backend: static

Generated Command:
  ls -la
  Confidence: 1.00
  Latency: 2ms
```

---

### 2. Explain Mode (`--explain` flag)

```rust
pub fn explain_command(command: &str) -> String {
    // Parse command and explain each component
    let parts = command.split_whitespace().collect::<Vec<_>>();

    match parts[0] {
        "find" => {
            format!(
                "find: Search for files\n\
                 -type f: Only regular files (not directories)\n\
                 -mtime -1: Modified in last 24 hours"
            )
        }
        "grep" => {
            format!(
                "grep: Search for text patterns\n\
                 -r: Recursive (search subdirectories)\n\
                 --include: Only search specific file types"
            )
        }
        _ => "No explanation available".to_string(),
    }
}
```

**Usage**:
```bash
caro --explain "find files modified today"

# Output:
Generated Command:
  find . -type f -mtime -1

Explanation:
  find: Search for files
  -type f: Only regular files (not directories)
  -mtime -1: Modified in last 24 hours
```

---

### 3. Dry Run Mode (`--dry-run` flag)

```rust
pub fn run(query: &str, dry_run: bool) -> Result<()> {
    let result = generate_command(query)?;

    if dry_run {
        println!("Would execute: {}", result.command);
        println!("(Not executing due to --dry-run flag)");
        return Ok(());
    }

    // Actually execute
    execute_command(&result.command)?;
    Ok(())
}
```

---

## Privacy & Compliance

### What We Collect (Opt-In Only)

**When Telemetry is ENABLED** (`caro config set telemetry.enabled true`):

✅ **Aggregate Metrics** (anonymous):
- Total commands generated (count)
- Success rate (percentage)
- Backend usage (static vs. embedded vs. ollama percentages)
- Latency distribution (p50, p95, p99)
- Error types (timeout, parse_error, etc.)

✅ **Crash Reports** (if user opts in):
- Stack trace (no user data)
- OS version, Rust version
- caro version

❌ **NEVER Collected**:
- Raw user queries
- Generated commands
- File paths
- User identity (username, email, IP)
- System hostname

---

### Data Storage & Deletion

**Local Storage**:
```
~/.cache/caro/
├── metrics.db         (SQLite, 30-day retention)
├── telemetry.log      (JSON logs, 7-day retention)
└── crashes/           (Crash dumps, manual deletion)
```

**Automatic Cleanup**:
```rust
pub fn cleanup_old_data() -> Result<()> {
    let cache_dir = dirs::cache_dir().unwrap().join("caro");

    // Delete metrics older than 30 days
    let metrics_db = cache_dir.join("metrics.db");
    if metrics_db.exists() {
        let conn = Connection::open(&metrics_db)?;
        conn.execute(
            "DELETE FROM events WHERE timestamp < ?1",
            [chrono::Utc::now().timestamp() - (30 * 86400)],
        )?;
    }

    // Delete logs older than 7 days
    let log_file = cache_dir.join("telemetry.log");
    if log_file.exists() {
        let cutoff = chrono::Utc::now() - chrono::Duration::days(7);
        // Rotate log file
    }

    Ok(())
}
```

**User Deletion**:
```bash
# Delete all telemetry data
caro telemetry clear

# Delete specific data
rm -rf ~/.cache/caro/metrics.db
```

---

## Local Development

### Development Logging Setup

**File: `.env` (local development)**
```bash
# Enable debug logging
RUST_LOG=caro=debug,tokio=info

# Pretty-print logs
CARO_LOG_FORMAT=pretty

# Enable all features
CARO_FEATURES=embedded,ollama

# Enable performance tracing
CARO_TRACE_ENABLED=1
```

**Run with Development Logging**:
```bash
# Load .env
source .env

# Run with debug logging
cargo run -- "list files"
```

---

### Testing Observability

**Code: Test Log Output**
```rust
#[cfg(test)]
mod tests {
    use tracing_test::traced_test;

    #[test]
    #[traced_test]
    fn test_command_generation_logs() {
        let agent = Agent::new();
        let result = agent.generate_command("list files").unwrap();

        // Assert logs contain expected entries
        assert!(logs_contain("generating command"));
        assert!(logs_contain("command generated successfully"));
    }
}
```

---

## Document History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2026-01-08 | Engineering Lead + SRE Lead | Initial comprehensive observability & monitoring infrastructure strategy |

---

**End of Document**
