name: LLM Evaluation Harness

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:  # Allow manual trigger

jobs:
  evaluate:
    runs-on: macos-latest  # For MLX backend support
    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Run Evaluation Harness
        id: evaluation
        run: |
          # Run evaluation and capture output
          # Exit code 0 = all pass, 1 = failures or regressions
          cargo test --test evaluation 2>&1 | tee evaluation.log || true

          # Extract pass rate from output
          PASS_RATE=$(grep "Passed:" evaluation.log | awk '{print $4}' | tr -d '()%')
          echo "pass_rate=$PASS_RATE" >> $GITHUB_OUTPUT

          # Check if evaluation passed
          if grep -q "✅ PASS" evaluation.log; then
            echo "status=pass" >> $GITHUB_OUTPUT
          else
            echo "status=fail" >> $GITHUB_OUTPUT
          fi

      - name: Check Evaluation Results
        env:
          PASS_RATE: ${{ steps.evaluation.outputs.pass_rate }}
          STATUS: ${{ steps.evaluation.outputs.status }}
        run: |
          echo "Pass Rate: $PASS_RATE%"
          echo "Status: $STATUS"

          # Informational only - don't block on test failures
          # The evaluation harness is new and pass rates will improve over time
          if [ "$STATUS" = "fail" ]; then
            echo "⚠️  Evaluation harness detected failures (pass rate: $PASS_RATE%)"
            echo "This is informational - not blocking the build"
          else
            echo "✅ All evaluation tests passed"
          fi

      - name: Upload Evaluation Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-results
          path: evaluation.log
          retention-days: 30
