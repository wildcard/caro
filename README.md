```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—        â•‘
   â•‘    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—       â•‘
   â•‘    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘       â•‘
   â•‘    â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘       â•‘
   â•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•       â•‘
   â•‘     â•šâ•â•â•â•â•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•        â•‘
   â•‘         â–² AI                          â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

<div align="center">

# âš¡ğŸ›¡ï¸ cmdai

**AI-Powered Commands. Human-Level Safety.**

[![AGPL License](https://img.shields.io/badge/license-AGPL--3.0-blue.svg)](LICENSE)
[![Rust](https://img.shields.io/badge/rust-1.75%2B-orange.svg)](https://www.rust-lang.org)
[![Development Stage](https://img.shields.io/badge/status-early%20development-yellow.svg)](https://github.com/wildcard/cmdai)

**Guard Rails for the Fast Lane** | **Think Fast. Stay Safe.**

[Quick Start](#-quick-start) Â· [Documentation](#-usage) Â· [Contributing](CONTRIBUTING.md) Â· [Brand Guide](brand-assets/interactive/brand-guide.html)

</div>

---

> **Early Development Stage** - Architecture defined, core implementation in progress

**cmdai** converts natural language descriptions into safe POSIX shell commands using local LLMs. Built with Rust for blazing-fast performance, single-binary distribution, and safety-first design.

**Every command validated. Every time.**

```bash
$ cmdai "list all PDF files in Downloads folder larger than 10MB"
Generated command:
  find ~/Downloads -name "*.pdf" -size +10M -ls

Execute this command? (y/N) y
```

## ğŸ“‹ Project Status

This project is in **active early development**. The architecture and module structure are in place, with implementation ongoing.

### âœ… Completed
- Core CLI structure with comprehensive argument parsing
- Modular architecture with trait-based backends
- **Embedded model backend with MLX (Apple Silicon) and CPU variants** âœ¨
- **Remote backend support (Ollama, vLLM) with automatic fallback** âœ¨
- Safety validation with pattern matching and risk assessment
- Configuration management with TOML support
- Interactive user confirmation flows
- Multiple output formats (JSON, YAML, Plain)
- Contract-based test structure with TDD methodology
- Multi-platform CI/CD pipeline

### ğŸš§ In Progress
- Model downloading and caching system
- Advanced command execution engine
- Performance optimization

### ğŸ“… Planned
- Multi-step goal completion
- Advanced context awareness
- Shell script generation
- Command history and learning

## âœ¨ Features (Planned & In Development)

- ğŸš€ **Instant startup** - Single binary with <100ms cold start (target)
- ğŸ§  **Local LLM inference** - Optimized for Apple Silicon with MLX
- ğŸ›¡ï¸ **Safety-first** - Comprehensive command validation framework
- ğŸ“¦ **Zero dependencies** - Self-contained binary distribution
- ğŸ¯ **Multiple backends** - Extensible backend system (MLX, vLLM, Ollama)
- ğŸ’¾ **Smart caching** - Hugging Face model management
- ğŸŒ **Cross-platform** - macOS, Linux, Windows support

## ğŸš€ Quick Start

### Prerequisites
- Rust 1.75+ with Cargo
- macOS with Apple Silicon (for MLX backend, optional)

### Building from Source

```bash
# Clone the repository
git clone https://github.com/wildcard/cmdai.git
cd cmdai

# Build the project
cargo build --release

# Run the CLI
./target/release/cmdai --version
```

### Development Commands

```bash
# Run tests
make test

# Format code
make fmt

# Run linter
make lint

# Build optimized binary
make build-release

# Run with debug logging
RUST_LOG=debug cargo run -- "your command"
```

## ğŸ“– Usage

### Basic Syntax
```bash
cmdai [OPTIONS] <PROMPT>
```

### Examples
```bash
# Basic command generation
cmdai "list all files in the current directory"

# With specific shell
cmdai --shell zsh "find large files"

# JSON output for scripting
cmdai --output json "show disk usage"

# Adjust safety level
cmdai --safety permissive "clean temporary files"

# Auto-confirm dangerous commands
cmdai --confirm "remove old log files"

# Verbose mode with timing info
cmdai --verbose "search for Python files"
```

### CLI Options

| Option | Description | Status |
|--------|-------------|--------|
| `-s, --shell <SHELL>` | Target shell (bash, zsh, fish, sh, powershell, cmd) | âœ… Implemented |
| `--safety <LEVEL>` | Safety level (strict, moderate, permissive) | âœ… Implemented |
| `-o, --output <FORMAT>` | Output format (json, yaml, plain) | âœ… Implemented |
| `-y, --confirm` | Auto-confirm dangerous commands | âœ… Implemented |
| `-v, --verbose` | Enable verbose output with timing | âœ… Implemented |
| `-c, --config <FILE>` | Custom configuration file | âœ… Implemented |
| `--show-config` | Display current configuration | âœ… Implemented |
| `--auto` | Execute without confirmation | ğŸ“… Planned |
| `--allow-dangerous` | Allow potentially dangerous commands | ğŸ“… Planned |
| `--verbose` | Enable verbose logging | âœ… Available |

### Examples (Target Functionality)

```bash
# Simple command generation
cmdai "compress all images in current directory"

# With specific backend
cmdai --backend mlx "find large log files"

# Verbose mode for debugging
cmdai --verbose "show disk usage"
```

## ğŸ—ï¸ Architecture

### Module Structure

```
cmdai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs              # CLI entry point
â”‚   â”œâ”€â”€ backends/            # LLM backend implementations
â”‚   â”‚   â”œâ”€â”€ mod.rs          # Backend trait definition
â”‚   â”‚   â”œâ”€â”€ mlx.rs          # Apple Silicon MLX backend
â”‚   â”‚   â”œâ”€â”€ vllm.rs         # vLLM remote backend
â”‚   â”‚   â””â”€â”€ ollama.rs       # Ollama local backend
â”‚   â”œâ”€â”€ safety/             # Command validation
â”‚   â”‚   â””â”€â”€ mod.rs          # Safety validator
â”‚   â”œâ”€â”€ cache/              # Model caching
â”‚   â”œâ”€â”€ config/             # Configuration management
â”‚   â”œâ”€â”€ cli/                # CLI interface
â”‚   â”œâ”€â”€ models/             # Data models
â”‚   â””â”€â”€ execution/          # Command execution
â”œâ”€â”€ tests/                   # Contract-based tests
â””â”€â”€ specs/                  # Project specifications
```

### Core Components

1. **CommandGenerator Trait** - Unified interface for all LLM backends
2. **SafetyValidator** - Command validation and risk assessment
3. **Backend System** - Extensible architecture for multiple inference engines
4. **Cache Manager** - Hugging Face model management (planned)

### Backend Architecture

```rust
#[async_trait]
trait CommandGenerator {
    async fn generate_command(&self, request: &CommandRequest) 
        -> Result<GeneratedCommand, GeneratorError>;
    async fn is_available(&self) -> bool;
    fn backend_info(&self) -> BackendInfo;
}
```

## ğŸ”§ Development

### Prerequisites
- Rust 1.75+ 
- Cargo
- Make (optional, for convenience commands)
- Docker (optional, for development container)

### Setup Development Environment

```bash
# Clone and enter the project
git clone https://github.com/wildcard/cmdai.git
cd cmdai

# Install dependencies and build
cargo build

# Run tests
cargo test

# Check formatting
cargo fmt -- --check

# Run clippy linter
cargo clippy -- -D warnings
```

### Backend Configuration

cmdai supports multiple inference backends with automatic fallback:

#### Embedded Backend (Default)
- **MLX**: Optimized for Apple Silicon Macs (M1/M2/M3)
- **CPU**: Cross-platform fallback using Candle framework
- Model: Qwen2.5-Coder-1.5B-Instruct (quantized)
- No external dependencies required

#### Remote Backends (Optional)
Configure in `~/.config/cmdai/config.toml`:

```toml
[backend]
primary = "embedded"  # or "ollama", "vllm"
enable_fallback = true

[backend.ollama]
base_url = "http://localhost:11434"
model_name = "codellama:7b"

[backend.vllm]
base_url = "http://localhost:8000"
model_name = "codellama/CodeLlama-7b-hf"
api_key = "optional-api-key"
```

### Project Configuration

The project uses several configuration files:
- `Cargo.toml` - Rust dependencies and build configuration
- `~/.config/cmdai/config.toml` - User configuration
- `clippy.toml` - Linter rules
- `rustfmt.toml` - Code formatting rules
- `deny.toml` - Dependency audit configuration

### Testing Strategy

The project uses contract-based testing:
- Unit tests for individual components
- Integration tests for backend implementations
- Contract tests to ensure trait compliance
- Property-based testing for safety validation

## ğŸ›¡ï¸ Safety System: Your Command Line Guardian

cmdai includes comprehensive safety validation to prevent dangerous operations. Every command is analyzed and color-coded before execution.

### Safety Level Visualization

```
â”Œâ”€ cmdai Safety Levels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                       â”‚
â”‚  SAFE      â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“ 100%   ğŸŸ¢ Green               â”‚
â”‚  MODERATE  â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘  60%   ğŸŸ¡ Yellow              â”‚
â”‚  HIGH      â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘  40%   ğŸŸ  Orange              â”‚
â”‚  CRITICAL  â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10%   ğŸ”´ Red                 â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What We Protect Against
- âœ… System destruction patterns (`rm -rf /`, `rm -rf ~`)
- âœ… Fork bombs detection (`:(){:|:&};:`)
- âœ… Disk operations (`mkfs`, `dd if=/dev/zero`)
- âœ… Privilege escalation detection (`sudo su`, `chmod 777 /`)
- âœ… Critical path protection (`/bin`, `/usr`, `/etc`)
- âœ… Command validation and sanitization

### How It Works
- **ğŸŸ¢ SAFE** - Normal operations, executes immediately
- **ğŸŸ¡ MODERATE** - Requires user confirmation in strict mode
- **ğŸŸ  HIGH** - Requires confirmation in moderate mode
- **ğŸ”´ CRITICAL** - Blocked by default, requires explicit override

**Ship faster. Sleep better.** Your terminal now has a brain.

### Safety Configuration
Configure safety levels in `~/.config/cmdai/config.toml`:
```toml
[safety]
enabled = true
level = "moderate"  # strict, moderate, or permissive
require_confirmation = true
custom_patterns = ["additional", "dangerous", "patterns"]
```

## ğŸ¤ Contributing

We welcome contributions! This is an early-stage project with many opportunities to contribute.

**Your terminal. Now with a brain.** Help us make it even smarter and safer.

### Areas for Contribution
- ğŸ”Œ **Backend implementations** - MLX, vLLM, Ollama support
- ğŸ›¡ï¸ **Safety pattern definitions** - Help protect against dangerous commands
- ğŸ§ª **Test coverage expansion** - TDD is our way
- ğŸ“š **Documentation improvements** - Clear docs = happy developers
- ğŸ› **Bug fixes and optimizations** - Make it faster, safer, better

### Getting Started
1. Read our [Contributor Onboarding Guide](culture/CONTRIBUTOR_ONBOARDING.md)
2. Check out [Community Guidelines](culture/COMMUNITY_GUIDELINES.md)
3. Fork the repository
4. Create a feature branch
5. Make your changes with tests
6. Ensure all tests pass (`make check`)
7. Submit a pull request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

**Think Fast. Stay Safe.** We value quality contributions over quick fixes.

## ğŸ“œ License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)** - see the [LICENSE](LICENSE) file for details.

### License Summary
- âœ… Commercial use
- âœ… Modification
- âœ… Distribution
- âœ… Private use
- âš ï¸ Network use requires source disclosure
- âš ï¸ Same license requirement
- âš ï¸ State changes documentation

## ğŸ™ Acknowledgments

- [MLX](https://github.com/ml-explore/mlx) - Apple's machine learning framework
- [vLLM](https://github.com/vllm-project/vllm) - High-performance LLM serving
- [Ollama](https://ollama.ai) - Local LLM runtime
- [Hugging Face](https://huggingface.co) - Model hosting and caching
- [clap](https://github.com/clap-rs/clap) - Command-line argument parsing

## ğŸ“ Support & Community

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/wildcard/cmdai/issues)
- ğŸ’¡ **Feature Requests**: [GitHub Discussions](https://github.com/wildcard/cmdai/discussions)
- ğŸ“– **Documentation**: See `/specs` directory for detailed specifications

## ğŸ—ºï¸ Roadmap

### Phase 1: Core Structure (Current)
- [x] CLI argument parsing
- [x] Module architecture
- [x] Backend trait system
- [ ] Basic command generation

### Phase 2: Safety & Validation
- [ ] Dangerous pattern detection
- [ ] POSIX compliance checking
- [ ] User confirmation workflows
- [ ] Risk assessment system

### Phase 3: Backend Integration
- [ ] vLLM HTTP API support
- [ ] Ollama local backend
- [ ] Response parsing
- [ ] Error handling

### Phase 4: MLX Optimization
- [ ] FFI bindings with cxx
- [ ] Metal Performance Shaders
- [ ] Unified memory handling
- [ ] Apple Silicon optimization

### Phase 5: Production Ready
- [ ] Comprehensive testing
- [ ] Performance optimization
- [ ] Binary distribution
- [ ] Package manager support

---

<div align="center">

## âš¡ğŸ›¡ï¸ Think Fast. Stay Safe.

**Built with Rust** Â· **Safety First** Â· **Open Source (AGPL-3.0)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  "Guard Rails for the Fast Lane"                   â”‚
â”‚                                                     â”‚
â”‚  Your AI assistant. Your safety validator.         â”‚
â”‚  Your terminal's new best friend.                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

[Website (planned)](https://cmdai.dev) Â· [GitHub](https://github.com/wildcard/cmdai) Â· [Interactive Brand Guide](brand-assets/interactive/brand-guide.html)

---

**1985 Vibes. 2025 Brains.**

> **Note**: This is an active development project. Features and APIs are subject to change. See the [specs](specs/) directory for detailed design documentation.

</div>