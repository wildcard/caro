//! Streaming Command Generation Contract Tests
//!
//! These tests verify the behavioral contracts for the streaming command generation system:
//! - Real-time chunk delivery with configurable timing
//! - Cancellation support and graceful handling
//! - Safety validation integration during streaming
//! - Performance requirements and buffer management
//! - Error handling and recovery mechanisms

use std::sync::Arc;
use std::time::{Duration, Instant};

use cmdai::backends::{BackendInfo, CommandGenerator, GeneratorError};
use cmdai::models::{BackendType, CommandRequest, GeneratedCommand, RiskLevel, ShellType};
use cmdai::streaming::{
    CancellationToken, StreamChunk, StreamingConfig, StreamingError, StreamingGenerator,
    StreamingWrapper,
};
use futures::StreamExt;

#[derive(Debug)]
struct TestBackend {
    command: String,
    latency_ms: u64,
    should_fail: bool,
}

impl TestBackend {
    fn new(command: &str) -> Self {
        Self {
            command: command.to_string(),
            latency_ms: 100,
            should_fail: false,
        }
    }

    fn with_latency(mut self, latency_ms: u64) -> Self {
        self.latency_ms = latency_ms;
        self
    }

    fn with_failure(mut self) -> Self {
        self.should_fail = true;
        self
    }
}

#[async_trait::async_trait]
impl CommandGenerator for TestBackend {
    async fn generate_command(
        &self,
        _request: &cmdai::models::CommandRequest,
    ) -> Result<GeneratedCommand, GeneratorError> {
        if self.should_fail {
            return Err(GeneratorError::GenerationFailed {
                details: "Test backend failure".to_string(),
            });
        }

        tokio::time::sleep(Duration::from_millis(self.latency_ms)).await;

        Ok(GeneratedCommand {
            command: self.command.clone(),
            explanation: "Generated by test backend".to_string(),
            safety_level: RiskLevel::Safe,
            estimated_impact: "Test impact".to_string(),
            alternatives: vec![],
            backend_used: "test".to_string(),
            generation_time_ms: self.latency_ms,
            confidence_score: 0.9,
        })
    }

    async fn is_available(&self) -> bool {
        !self.should_fail
    }

    fn backend_info(&self) -> BackendInfo {
        BackendInfo {
            backend_type: BackendType::Embedded,
            model_name: "test-backend".to_string(),
            supports_streaming: true,
            max_tokens: 100,
            typical_latency_ms: self.latency_ms,
            memory_usage_mb: 50,
            version: "test".to_string(),
        }
    }

    async fn shutdown(&self) -> Result<(), GeneratorError> {
        Ok(())
    }
}

/// Contract: Streaming generator creation and configuration
#[tokio::test]
async fn test_streaming_generator_creation() {
    // Valid configuration should succeed
    let backend = Arc::new(TestBackend::new("echo hello"));
    let config = StreamingConfig::default();
    let generator = StreamingGenerator::new(backend, config).await;
    assert!(
        generator.is_ok(),
        "Valid configuration should create generator"
    );

    // Invalid configuration should fail
    let backend = Arc::new(TestBackend::new("echo hello"));
    let invalid_config = StreamingConfig {
        chunk_timeout_ms: 0, // Invalid
        ..StreamingConfig::default()
    };
    let result = StreamingGenerator::new(backend, invalid_config).await;
    assert!(result.is_err(), "Invalid configuration should fail");

    if let Err(StreamingError::InvalidConfig { message }) = result {
        assert!(message.contains("positive"));
    } else {
        panic!("Expected InvalidConfig error");
    }
}

/// Contract: Real-time chunk delivery with timing guarantees
#[tokio::test]
async fn test_streaming_chunk_delivery() {
    let backend = Arc::new(TestBackend::new("find /home -name '*.txt' -type f"));
    let config = StreamingConfig {
        chunk_timeout_ms: 50,
        min_chunk_size: 3,
        debounce_ms: 10,
        ..StreamingConfig::default()
    };
    let generator = StreamingGenerator::new(backend, config).await.unwrap();

    let request = CommandRequest::new("find text files", ShellType::Bash);
    let (mut stream, _token) = generator.generate_streaming(&request).await.unwrap();

    let start_time = Instant::now();
    let mut chunk_times = Vec::new();
    let mut chunks_received = 0;
    let mut total_content = String::new();
    let mut final_result = None;

    while let Some(chunk_result) = stream.next().await {
        let chunk_time = start_time.elapsed();
        chunk_times.push(chunk_time);

        let chunk = chunk_result.unwrap();
        match chunk {
            StreamChunk::Partial {
                content,
                confidence,
                ..
            } => {
                assert!(!content.is_empty(), "Partial chunks should not be empty");
                assert!(
                    confidence >= 0.0 && confidence <= 1.0,
                    "Confidence should be in [0,1]"
                );
                total_content = content; // Keep the accumulated content
                chunks_received += 1;
            }
            StreamChunk::Complete {
                final_command,
                generation_stats,
            } => {
                assert_eq!(final_command.command, "find /home -name '*.txt' -type f");
                assert!(
                    generation_stats.total_chunks > 0,
                    "Should have generated chunks"
                );
                assert!(
                    generation_stats.total_duration_ms > 0,
                    "Should track duration"
                );
                final_result = Some(final_command);
                break;
            }
            StreamChunk::Error { .. } => panic!("Unexpected error chunk"),
            StreamChunk::Cancelled { .. } => panic!("Unexpected cancellation"),
            StreamChunk::SafetyWarning { .. } => {
                // Safety warnings are acceptable
            }
        }
    }

    // Verify streaming behavior
    assert!(chunks_received > 0, "Should receive partial chunks");
    assert!(final_result.is_some(), "Should receive final result");

    // Verify timing constraints (chunks should arrive at reasonable intervals)
    if chunk_times.len() > 1 {
        for window in chunk_times.windows(2) {
            let interval = window[1] - window[0];
            assert!(
                interval <= Duration::from_millis(200), // Allow some variance
                "Chunk interval {:?} should be within reasonable bounds",
                interval
            );
        }
    }
}

/// Contract: Cancellation support and graceful handling
#[tokio::test]
async fn test_streaming_cancellation() {
    let backend = Arc::new(TestBackend::new(
        "very long command that takes time to generate",
    ));
    let config = StreamingConfig {
        chunk_timeout_ms: 100, // Slower chunks for cancellation testing
        min_chunk_size: 5,
        ..StreamingConfig::default()
    };
    let generator = StreamingGenerator::new(backend, config).await.unwrap();

    let request = CommandRequest::new("long operation", ShellType::Bash);
    let (mut stream, cancellation_token) = generator.generate_streaming(&request).await.unwrap();

    // Schedule cancellation after a short delay
    let cancel_handle = tokio::spawn(async move {
        tokio::time::sleep(Duration::from_millis(150)).await;
        cancellation_token.cancel().unwrap();
    });

    let mut received_chunks = 0;
    let mut was_cancelled = false;

    while let Some(chunk_result) = stream.next().await {
        let chunk = chunk_result.unwrap();
        match chunk {
            StreamChunk::Partial { .. } => {
                received_chunks += 1;
            }
            StreamChunk::Complete { .. } => {
                // If we complete before cancellation, that's also valid
                break;
            }
            StreamChunk::Cancelled {
                partial_content,
                reason,
            } => {
                assert!(!reason.is_empty(), "Cancellation reason should be provided");
                was_cancelled = true;
                break;
            }
            StreamChunk::Error { .. } => panic!("Unexpected error during cancellation test"),
            StreamChunk::SafetyWarning { .. } => {
                // Safety warnings are acceptable
            }
        }
    }

    cancel_handle.abort(); // Clean up the cancellation task

    // Either cancellation occurred, or generation completed quickly
    // Both are valid behaviors
    if was_cancelled {
        assert!(
            received_chunks >= 0,
            "Should handle cancellation gracefully"
        );
    }
}

/// Contract: Safety validation integration during streaming
#[tokio::test]
async fn test_streaming_safety_integration() {
    let backend = Arc::new(TestBackend::new("rm -rf /tmp/dangerous_file"));
    let config = StreamingConfig {
        enable_streaming_safety: true,
        yield_unsafe_partial: false, // Don't yield unsafe partial content
        chunk_timeout_ms: 50,
        min_chunk_size: 3,
        ..StreamingConfig::default()
    };
    let generator = StreamingGenerator::new(backend, config).await.unwrap();

    let request = CommandRequest::new("delete file", ShellType::Bash);
    let (mut stream, _token) = generator.generate_streaming(&request).await.unwrap();

    let mut safety_warnings = 0;
    let mut partial_chunks = 0;
    let mut final_result = None;

    while let Some(chunk_result) = stream.next().await {
        let chunk = chunk_result.unwrap();
        match chunk {
            StreamChunk::Partial { is_safe, .. } => {
                // If streaming safety is enabled, partial chunks might be marked as unsafe
                partial_chunks += 1;
                // We don't assert is_safe here because rm commands might be flagged
            }
            StreamChunk::Complete { final_command, .. } => {
                assert_eq!(final_command.command, "rm -rf /tmp/dangerous_file");
                final_result = Some(final_command);
                break;
            }
            StreamChunk::SafetyWarning {
                warning,
                risk_level,
                ..
            } => {
                assert!(!warning.is_empty(), "Safety warning should have content");
                assert!(matches!(
                    risk_level,
                    RiskLevel::Moderate | RiskLevel::High | RiskLevel::Critical
                ));
                safety_warnings += 1;
            }
            StreamChunk::Error { .. } => panic!("Unexpected error chunk"),
            StreamChunk::Cancelled { .. } => panic!("Unexpected cancellation"),
        }
    }

    assert!(final_result.is_some(), "Should complete generation");
    // Note: Safety warnings depend on the specific command and safety configuration
    // The important thing is that the system doesn't crash and handles them gracefully
}

/// Contract: Performance requirements and buffer management
#[tokio::test]
async fn test_streaming_performance() {
    let long_command = "find /usr -type f -name '*.so' | xargs ls -la | sort -k5 -n | tail -20";
    let backend = Arc::new(TestBackend::new(long_command).with_latency(50));

    let config = StreamingConfig {
        chunk_timeout_ms: 25, // Fast chunks
        min_chunk_size: 2,
        max_buffer_size: 1024,
        debounce_ms: 10,
        max_streaming_duration_ms: 5000,
        ..StreamingConfig::default()
    };
    let generator = StreamingGenerator::new(backend, config).await.unwrap();

    let request = CommandRequest::new("complex find operation", ShellType::Bash);
    let start_time = Instant::now();
    let (mut stream, _token) = generator.generate_streaming(&request).await.unwrap();

    let mut total_chunks = 0;
    let mut max_chunk_interval = Duration::from_millis(0);
    let mut last_chunk_time = start_time;

    while let Some(chunk_result) = stream.next().await {
        let chunk_time = Instant::now();
        let interval = chunk_time.duration_since(last_chunk_time);
        max_chunk_interval = max_chunk_interval.max(interval);
        last_chunk_time = chunk_time;

        let chunk = chunk_result.unwrap();
        match chunk {
            StreamChunk::Partial {
                accumulated_length, ..
            } => {
                total_chunks += 1;
                assert!(
                    accumulated_length <= 1024, // Should respect buffer limits
                    "Accumulated length {} should not exceed buffer size",
                    accumulated_length
                );
            }
            StreamChunk::Complete {
                generation_stats, ..
            } => {
                let total_time = start_time.elapsed();

                // Performance assertions
                assert!(
                    total_time <= Duration::from_secs(10),
                    "Total generation time {:?} should be reasonable",
                    total_time
                );
                assert!(
                    generation_stats.total_chunks > 0,
                    "Should have generated chunks"
                );
                assert!(
                    generation_stats.average_chunk_size > 0.0,
                    "Should have positive average chunk size"
                );
                break;
            }
            StreamChunk::Error { .. } | StreamChunk::Cancelled { .. } => break,
            StreamChunk::SafetyWarning { .. } => {
                // Safety warnings don't count toward performance metrics
            }
        }
    }

    // Performance requirements
    assert!(total_chunks > 0, "Should generate chunks for long commands");
    assert!(
        max_chunk_interval <= Duration::from_millis(200),
        "Maximum chunk interval {:?} should be reasonable",
        max_chunk_interval
    );
}

/// Contract: Error handling and recovery mechanisms
#[tokio::test]
async fn test_streaming_error_handling() {
    // Test backend failure during generation
    let failing_backend = Arc::new(TestBackend::new("test").with_failure());
    let config = StreamingConfig::default();
    let generator = StreamingGenerator::new(failing_backend, config)
        .await
        .unwrap();

    let request = CommandRequest::new("test command", ShellType::Bash);
    let (mut stream, _token) = generator.generate_streaming(&request).await.unwrap();

    let mut error_received = false;
    while let Some(chunk_result) = stream.next().await {
        let chunk = chunk_result.unwrap();
        match chunk {
            StreamChunk::Error {
                error,
                partial_content,
                recovery_suggestion,
            } => {
                assert!(!error.is_empty(), "Error should have description");
                assert!(
                    recovery_suggestion.is_some(),
                    "Should provide recovery suggestion"
                );
                error_received = true;
                break;
            }
            StreamChunk::Partial { .. } => {
                // Partial chunks before error are acceptable
            }
            StreamChunk::Complete { .. } => {
                panic!("Should not complete successfully with failing backend");
            }
            StreamChunk::Cancelled { .. } => {
                panic!("Should not be cancelled in error test");
            }
            StreamChunk::SafetyWarning { .. } => {
                // Safety warnings are acceptable
            }
        }
    }

    assert!(
        error_received,
        "Should receive error chunk for failing backend"
    );
}

/// Contract: Configuration validation and adaptation
#[tokio::test]
async fn test_streaming_configuration_validation() {
    let backend = Arc::new(TestBackend::new("echo test"));

    // Test invalid configurations
    let invalid_configs = vec![
        StreamingConfig {
            chunk_timeout_ms: 0,
            ..StreamingConfig::default()
        },
        StreamingConfig {
            max_buffer_size: 0,
            ..StreamingConfig::default()
        },
    ];

    for config in invalid_configs {
        let result = StreamingGenerator::new(backend.clone(), config).await;
        assert!(result.is_err(), "Invalid configuration should be rejected");
    }

    // Test valid configuration presets
    let valid_configs = vec![
        StreamingConfig::default(),
        StreamingConfig::interactive(),
        StreamingConfig::batch(),
    ];

    for config in valid_configs {
        let result = StreamingGenerator::new(backend.clone(), config).await;
        assert!(result.is_ok(), "Valid configuration should be accepted");
    }
}

/// Contract: Wrapper functionality for non-streaming backends
#[tokio::test]
async fn test_streaming_wrapper_functionality() {
    let backend = TestBackend::new("ls -la /tmp");
    let wrapper = StreamingWrapper::new(backend);

    // Verify wrapper preserves backend functionality
    assert!(wrapper.is_available().await);
    assert!(wrapper.backend_info().supports_streaming);

    let request = CommandRequest::new("list files", ShellType::Bash);
    let command_result = wrapper.generate_command(&request).await;
    assert!(command_result.is_ok());

    // Test shutdown
    let shutdown_result = wrapper.shutdown().await;
    assert!(shutdown_result.is_ok());
}

/// Contract: Multiple concurrent streaming sessions
#[tokio::test]
async fn test_concurrent_streaming_sessions() {
    let backend = Arc::new(TestBackend::new("echo concurrent test"));
    let config = StreamingConfig::interactive();
    let generator = Arc::new(StreamingGenerator::new(backend, config).await.unwrap());

    let mut handles = Vec::new();

    // Start multiple concurrent streaming sessions
    for i in 0..3 {
        let generator_clone = Arc::clone(&generator);
        let handle = tokio::spawn(async move {
            let request = CommandRequest::new(format!("test command {}", i), ShellType::Bash);
            let (mut stream, _token) = generator_clone.generate_streaming(&request).await.unwrap();

            let mut completed = false;
            while let Some(chunk_result) = stream.next().await {
                let chunk = chunk_result.unwrap();
                if let StreamChunk::Complete { .. } = chunk {
                    completed = true;
                    break;
                }
            }
            completed
        });
        handles.push(handle);
    }

    // Wait for all sessions to complete
    for (i, handle) in handles.into_iter().enumerate() {
        let completed = handle.await.expect("Task should not panic");
        assert!(completed, "Session {} should complete successfully", i);
    }
}

/// Contract: Timeout handling for long-running generations
#[tokio::test]
async fn test_streaming_timeout_handling() {
    let backend = Arc::new(TestBackend::new("long running command").with_latency(200));
    let config = StreamingConfig {
        max_streaming_duration_ms: 300, // Short timeout
        chunk_timeout_ms: 100,
        ..StreamingConfig::default()
    };
    let generator = StreamingGenerator::new(backend, config).await.unwrap();

    let request = CommandRequest::new("slow operation", ShellType::Bash);
    let (mut stream, _token) = generator.generate_streaming(&request).await.unwrap();

    let start_time = Instant::now();
    let mut timed_out = false;

    while let Some(chunk_result) = stream.next().await {
        match chunk_result {
            Ok(StreamChunk::Complete { .. }) => {
                // Completed before timeout
                break;
            }
            Ok(StreamChunk::Partial { .. }) => {
                // Continue receiving chunks
            }
            Ok(StreamChunk::Error { error, .. }) => {
                if error.contains("timeout") || error.contains("Timeout") {
                    timed_out = true;
                }
                break;
            }
            Ok(_) => {
                // Other chunk types
            }
            Err(StreamingError::Timeout { .. }) => {
                timed_out = true;
                break;
            }
            Err(_) => break,
        }
    }

    let total_time = start_time.elapsed();

    // Either the operation timed out, or completed quickly
    // The important thing is it doesn't hang indefinitely
    assert!(
        total_time <= Duration::from_secs(2),
        "Operation should not hang indefinitely, took {:?}",
        total_time
    );
}
