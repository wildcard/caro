# Work Packages: LLM Evaluation Harness

**Inputs**: Design documents from `/kitty-specs/025-llm-evaluation-harness/`
**Prerequisites**: plan.md (complete), spec.md (user stories), research.md (complete), data-model.md (complete), contracts/ (complete), quickstart.md (complete)

**Tests**: This feature IS the testing infrastructure. Will follow TDD for harness implementation itself (constitution Principle III special case).

**Organization**: Fine-grained subtasks (`Txxx`) roll up into work packages (`WPxx`). Each work package must be independently deliverable and testable.

**Prompt Files**: Each work package references a matching prompt file in `/tasks/planned/` generated by `/spec-kitty.tasks`. Treat this file as the high-level checklist; keep deep implementation detail inside the prompt files.

## Subtask Format: `[Txxx] [P?] Description`
- **[P]** indicates the subtask can proceed in parallel (different files/components).
- Include precise file paths or modules.

## Path Conventions
- **Evaluation harness**: `tests/evaluation/` (all new code)
- **Existing modules**: `src/backends/`, `src/safety/`, `src/models/` (reused, no changes)

---

## Work Package WP01: Project Setup & Directory Structure (Priority: P0)

**Goal**: Establish evaluation harness directory structure and add toml dependency.
**Independent Test**: `cargo build` succeeds with new dependency; `tests/evaluation/` directory exists with proper module structure.
**Prompt**: `/tasks/planned/WP01-project-setup.md`

### Included Subtasks
- [x] T001 Add `toml = "0.8"` dependency to `Cargo.toml` under `[dev-dependencies]`
- [x] T002 Create `tests/evaluation/` directory structure
- [x] T003 Create `tests/evaluation/mod.rs` with module declarations
- [x] T004 Create empty stub files: `dataset.rs`, `harness.rs`, `validators.rs`, `reporter.rs`
- [x] T005 Verify `cargo build` succeeds and can import new modules

### Implementation Notes
1. Edit `Cargo.toml` to add toml crate (dev dependency only)
2. Create directory: `tests/evaluation/`
3. Create `mod.rs` with: `pub mod dataset; pub mod harness; pub mod validators; pub mod reporter;`
4. Create 4 empty Rust files with minimal stub (e.g., `// Dataset loading logic`)
5. Run `cargo build` to verify module structure

### Parallel Opportunities
- All subtasks are sequential (setup phase)

### Dependencies
- None (starting package)

### Risks & Mitigations
- **Risk**: Module visibility issues in test directory
- **Mitigation**: Follow existing `tests/` structure patterns; use `pub mod` declarations

---

## Work Package WP02: Test Dataset Infrastructure (Priority: P0)

**Goal**: Implement TOML dataset loading with validation and create initial test dataset.
**Independent Test**: Dataset loader can parse test_cases.toml and validate test case structure; fails gracefully on malformed input.
**Prompt**: `/tasks/planned/WP02-dataset-infrastructure.md`

### Included Subtasks
- [x] T006 Define `TestCase` struct in `dataset.rs` matching data-model.md
- [x] T007 Define `Category` enum (Correctness, Safety, Posix) with serde annotations
- [x] T008 Define `TestDataset` struct with version and test_cases Vec
- [x] T009 Implement `TestDataset::from_toml()` with error handling
- [x] T010 Add validation logic: unique IDs, non-empty required fields
- [x] T011 Create `tests/evaluation/test_cases.toml` with 10 initial examples
- [x] T012 Write unit test for dataset loading success case
- [x] T013 Write unit test for duplicate ID detection
- [x] T014 Write unit test for malformed TOML error handling

### Implementation Notes
- Use `serde::Deserialize` for automatic TOML parsing
- Validation runs in `TestDataset::validate()` called by `from_toml()`
- Initial 10 test cases cover: 6 correctness, 2 safety, 2 POSIX examples
- Follow TOML structure from research.md

### Parallel Opportunities
- T011 (create TOML file) can proceed in parallel with T006-T010 (struct implementation)

### Dependencies
- Depends on WP01

### Risks & Mitigations
- **Risk**: TOML parsing errors hard to diagnose
- **Mitigation**: Use `toml::from_str` error messages; add line number context in error handling

---

## Work Package WP03: Command Normalization & Comparison (Priority: P0)

**Goal**: Implement semantic command equivalence checking with normalization.
**Independent Test**: Normalizer correctly handles whitespace, flag sorting; comparison logic recognizes semantically equivalent commands.
**Prompt**: `/tasks/planned/WP03-command-normalization.md`

### Included Subtasks
- [x] T015 Implement `normalize_command()` function in `validators.rs`
- [x] T016 Add whitespace normalization (multiple spaces ‚Üí single)
- [x] T017 Add flag consolidation and sorting (`ls -l -a` ‚Üí `ls -al`)
- [x] T018 Implement `commands_match()` comparison function
- [x] T019 Write unit test: whitespace normalization
- [x] T020 Write unit test: flag order equivalence (`ls -la` == `ls -al`)
- [x] T021 Write unit test: flag consolidation (`ls -l -a` == `ls -la`)
- [x] T022 Write unit test: exact match after normalization

### Implementation Notes
- Normalization strategy from research.md Task 2
- Use regex for whitespace: `\s+` ‚Üí ` `
- Flag sorting: extract single-letter flags, sort alphabetically, recombine
- Known limitation: Long-form flags (`--all`) not normalized in MVP

### Parallel Opportunities
- Unit tests (T019-T022) can be written in parallel once implementation is stable

### Dependencies
- Depends on WP01 (validators.rs exists)

### Risks & Mitigations
- **Risk**: Over-normalization breaks valid command differences
- **Mitigation**: Only normalize whitespace and single-letter flag order; preserve everything else

---

## Work Package WP04: Safety & POSIX Validators (Priority: P0)

**Goal**: Integrate caro::safety module and implement POSIX compliance checker.
**Independent Test**: Safety validator correctly detects dangerous patterns; POSIX checker identifies bash/zsh-specific syntax.
**Prompt**: `/tasks/planned/WP04-safety-posix-validators.md`

### Included Subtasks
- [x] T023 Import `caro::safety::SafetyValidator` in `validators.rs`
- [x] T024 Create `validate_safety()` wrapper function
- [x] T025 Implement `is_posix_compliant()` function with regex patterns
- [x] T026 Add bash-specific pattern detection (`[[`, `function`, `{1..10}`, `<()`)
- [x] T027 Add zsh-specific pattern detection (`**/`, `=()`)
- [x] T028 Write unit test: safety detection for `rm -rf /`
- [x] T029 Write unit test: safety detection for safe command `ls -la`
- [x] T030 Write unit test: POSIX compliant command `[ -f file ]`
- [x] T031 Write unit test: bash-specific `[[ -f file ]]` detected
- [x] T032 Write unit test: brace expansion `{1..10}` detected

### Implementation Notes
- Reuse existing `caro::safety` module (no changes to production code)
- POSIX checker uses regex patterns from research.md Task 4
- Return boolean: true = compliant, false = shell-specific

### Parallel Opportunities
- T023-T024 (safety) and T025-T027 (POSIX) can proceed in parallel
- Unit tests can be written in parallel once validators are implemented

### Dependencies
- Depends on WP01 (validators.rs exists)

### Risks & Mitigations
- **Risk**: POSIX regex patterns miss edge cases
- **Mitigation**: Start with common patterns; expand iteratively based on test dataset findings

---

## Work Package WP05: Evaluation Runner Core Logic (Priority: P1) üéØ MVP

**Goal**: Implement evaluation harness that runs test cases against backends and collects results.
**Independent Test**: Harness can execute single test case; backend integration works; errors handled gracefully.
**Prompt**: `/tasks/planned/WP05-evaluation-runner.md`

### Included Subtasks
- [x] T033 Define `run_evaluation()` function signature in `harness.rs`
- [x] T034 Implement backend initialization (MLX primary)
- [x] T035 Create test case execution loop
- [x] T036 Integrate `caro::backends::BackendTrait` for command generation
- [x] T037 Call validators (normalization, safety, POSIX) on generated command
- [x] T038 Collect pass/fail results per test case
- [x] T039 Handle backend timeout errors gracefully
- [x] T040 Handle malformed backend responses
- [x] T041 Write integration test: run single test case
- [x] T042 Write integration test: handle backend timeout

### Implementation Notes
- Use `tokio` for async backend calls (existing dependency)
- Timeout logic: 30s per test case (configurable)
- Results stored as `Vec<TestResult>` intermediate structure
- Backend selection: MLX hardcoded for MVP; P2 adds multi-backend support

### Parallel Opportunities
- T039-T040 (error handling) can proceed after T033-T038 (happy path) is stable

### Dependencies
- Depends on WP02 (TestCase struct), WP03 (normalization), WP04 (validators)

### Risks & Mitigations
- **Risk**: Backend hangs on specific prompts
- **Mitigation**: Enforce 30s timeout; mark as BackendError, continue evaluation

---

## Work Package WP06: Metrics Calculation & Result Aggregation (Priority: P1) üéØ MVP

**Goal**: Calculate CSR, safety accuracy, POSIX compliance rate and generate EvaluationResult struct.
**Independent Test**: Metrics calculations are correct; CategoryResult breakdown matches manual calculation.
**Prompt**: `/tasks/planned/WP06-metrics-calculation.md`

### Included Subtasks
- [x] T043 Define `EvaluationResult` struct in `harness.rs` (from data-model.md)
- [x] T044 Define `CategoryResult` and `FailedCase` structs
- [x] T045 Define `FailureReason` enum with all variants
- [x] T046 Implement `calculate_csr()` function
- [x] T047 Implement `calculate_safety_accuracy()` function
- [x] T048 Implement `calculate_posix_compliance_rate()` function
- [x] T049 Implement per-category breakdown logic
- [x] T050 Collect failed_cases with detailed information
- [x] T051 Write unit test: CSR calculation (47/50 = 0.948)
- [x] T052 Write unit test: safety accuracy (8/8 = 1.0)
- [x] T053 Write unit test: per-category breakdown validation

### Implementation Notes
- CSR formula: `passed / total` (baseline: 0.948 from ROADMAP.md)
- Safety accuracy: `correct_safety_detections / total_safety_tests`
- POSIX compliance: `correct_posix_detections / total_posix_tests`
- Generate timestamp with `chrono::Utc::now().to_rfc3339()`
- Extract caro_version from `env!("CARGO_PKG_VERSION")`

### Parallel Opportunities
- T046, T047, T048 (metric functions) can be implemented in parallel

### Dependencies
- Depends on WP05 (evaluation results available)

### Risks & Mitigations
- **Risk**: Float precision errors in percentage calculations
- **Mitigation**: Use f64 for all metrics; round only for display

---

## Work Package WP07: JSON & Console Output (Priority: P1) üéØ MVP

**Goal**: Implement JSON serialization and human-readable console formatting.
**Independent Test**: JSON output validates against contracts/evaluation_result_schema.json; console output is clear and actionable.
**Prompt**: `/tasks/planned/WP07-output-formatting.md`

### Included Subtasks
- [x] T054 Add serde Serialize derive to all result structs
- [x] T055 Implement `output_json()` function in `reporter.rs`
- [x] T056 Implement `output_console()` function with formatted display
- [x] T057 Add CSR threshold indicators (‚úÖ ‚â•94.8%, ‚ö†Ô∏è 90-94.7%, ‚ùå <90%)
- [x] T058 Format failed cases with clear diff-style output
- [x] T059 Write unit test: JSON serialization produces valid schema
- [x] T060 Write unit test: console output includes all required sections
- [x] T061 Validate JSON against contracts/evaluation_result_schema.json

### Implementation Notes
- JSON output uses `serde_json::to_string_pretty()`
- Console output format from quickstart.md
- Include color coding: green (pass), yellow (warning), red (fail)
- Console sections: header, metrics, per-category, failed cases

### Parallel Opportunities
- T055 (JSON) and T056-T058 (console) can proceed in parallel

### Dependencies
- Depends on WP06 (EvaluationResult struct complete)

### Risks & Mitigations
- **Risk**: JSON schema drift from data-model.md
- **Mitigation**: Run JSON schema validation test in CI

---

## Work Package WP08: Integration Test & Cargo Test Integration (Priority: P1) üéØ MVP

**Goal**: Create cargo test integration and end-to-end evaluation test.
**Independent Test**: `cargo test --test evaluation` runs successfully; CI/CD integration verified.
**Prompt**: `/tasks/planned/WP08-integration-test.md`

### Included Subtasks
- [x] T062 Create `tests/evaluation/mod.rs` main test entry point
- [x] T063 Implement `#[test] fn test_run_evaluation()`
- [x] T064 Load test dataset from test_cases.toml
- [x] T065 Run full evaluation harness
- [x] T066 Assert CSR meets baseline (‚â•0.948 for passing dataset)
- [x] T067 Assert safety accuracy = 1.0
- [x] T068 Assert POSIX compliance ‚â• 0.95
- [x] T069 Add GitHub Actions workflow for evaluation tests
- [x] T070 Configure CI to fail if CSR < 0.90

### Implementation Notes
- Test function calls all modules: dataset ‚Üí harness ‚Üí validators ‚Üí reporter
- Use existing test dataset (10 examples from WP02, expanded in WP09)
- GitHub Actions: add step to `cargo test --test evaluation`
- CI failure threshold: CSR < 0.90 blocks merge

### Parallel Opportunities
- T069-T070 (CI/CD) can proceed in parallel with T062-T068 (test implementation)

### Dependencies
- Depends on WP02, WP03, WP04, WP05, WP06, WP07 (all core modules complete)

### Risks & Mitigations
- **Risk**: Flaky tests due to backend variability
- **Mitigation**: Use deterministic test dataset; mock backend for unit tests if needed

---

## Work Package WP09: Test Dataset Curation (Priority: P1) üéØ MVP

**Goal**: Expand test dataset to 50+ diverse examples covering all categories.
**Independent Test**: Dataset has ‚â•50 examples; coverage includes common commands, edge cases, safety patterns, POSIX violations.
**Prompt**: `/tasks/planned/WP09-dataset-curation.md`

### Included Subtasks
- [x] T071 Add 20 correctness examples (file ops, text processing, system info)
- [x] T072 Add 10 safety examples (dangerous patterns, root operations)
- [x] T073 Add 10 POSIX examples (bash/zsh-specific syntax)
- [x] T074 Add 10 edge case examples (quoting, pipes, redirects)
- [x] T075 Document rationale in notes field for each test case
- [x] T076 Validate all test cases parse correctly
- [x] T077 Run evaluation to verify baseline CSR ‚â• 0.948
- [x] T078 Review failed cases and adjust expected commands if needed

### Implementation Notes
- Coverage goals from quickstart.md curation guidelines
- Categories: 30 correctness (60%), 10 safety (20%), 10 POSIX (20%)
- Include common commands: ls, grep, find, sed, awk, tar, ps, df, rm, cp, mv
- Safety examples: rm -rf /, sudo commands, privilege escalation
- POSIX violations: [[, function keyword, brace expansion, process substitution

### Parallel Opportunities
- T071, T072, T073, T074 (different categories) can be curated in parallel

### Dependencies
- Depends on WP08 (evaluation test exists to validate dataset)

### Risks & Mitigations
- **Risk**: Subjective "correct" commands cause debate
- **Mitigation**: Document rationale in notes; prefer commands from coreutils documentation

---

## Work Package WP10: Multi-Backend Consistency (DEFERRED)

**Status**: ‚è∏Ô∏è **DEFERRED TO FUTURE RELEASE** (v1.2.0 or later)

**Reason**: MVP (v1.1.0) focuses on MLX backend only for Apple Silicon. Multi-backend support (vLLM, Ollama) is Phase 3 - P2 Features work.

**Original Goal**: Add vLLM and Ollama backend support; implement cross-backend consistency testing.

**Location**: Moved to `/future_work/WP10-multi-backend.md`

**Prerequisites**: WP01-WP09 complete ‚úÖ

**Future Scope** (when resumed):
- Add vLLM and Ollama backend integration
- Implement backend selector logic (configurable)
- Create cross-backend consistency tests
- Calculate command similarity scores
- Report divergence when similarity < 95%

See `/future_work/README.md` for full details and rationale.

---

## Dependency & Execution Summary

**Sequence**:
1. **Setup**: WP01 ‚Üí WP02 ‚Üí WP03 ‚Üí WP04 (foundational infrastructure)
2. **Core MVP**: WP05 ‚Üí WP06 ‚Üí WP07 ‚Üí WP08 (evaluation harness)
3. **Data Quality**: WP09 (dataset curation - can overlap with WP05-WP08)
4. **P2 Feature**: WP10 (multi-backend - optional for v1.1.0)

**Parallelization**:
- After WP01: WP02, WP03, WP04 can proceed in parallel (different files)
- After WP04: WP05 is critical path; WP09 can start in parallel
- After WP05: WP06 ‚Üí WP07 ‚Üí WP08 are sequential
- WP10 can proceed independently after WP05

**MVP Scope** (User Story 1 - P1):
- **Must Have**: WP01, WP02, WP03, WP04, WP05, WP06, WP07, WP08, WP09
- **Deferred to P2**: WP10 (multi-backend consistency)

**v1.1.0 Release Criteria**:
- All MVP packages complete (WP01-WP09)
- `cargo test --test evaluation` passes
- CSR ‚â• 94.8% on 50+ test dataset
- Safety accuracy = 100%
- POSIX compliance ‚â• 95%
- CI/CD integration working

---

## Subtask Index (Reference)

| Subtask ID | Summary | Work Package | Priority | Parallel? |
|------------|---------|--------------|----------|-----------|
| T001 | Add toml dependency | WP01 | P0 | No |
| T002 | Create directory structure | WP01 | P0 | No |
| T003 | Create mod.rs | WP01 | P0 | No |
| T004 | Create stub files | WP01 | P0 | No |
| T005 | Verify cargo build | WP01 | P0 | No |
| T006 | Define TestCase struct | WP02 | P0 | No |
| T007 | Define Category enum | WP02 | P0 | No |
| T008 | Define TestDataset struct | WP02 | P0 | No |
| T009 | Implement from_toml() | WP02 | P0 | No |
| T010 | Add validation logic | WP02 | P0 | No |
| T011 | Create test_cases.toml | WP02 | P0 | [P] |
| T012 | Unit test: loading success | WP02 | P0 | [P] |
| T013 | Unit test: duplicate ID | WP02 | P0 | [P] |
| T014 | Unit test: malformed TOML | WP02 | P0 | [P] |
| T015 | Implement normalize_command() | WP03 | P0 | No |
| T016 | Whitespace normalization | WP03 | P0 | No |
| T017 | Flag consolidation/sorting | WP03 | P0 | No |
| T018 | Implement commands_match() | WP03 | P0 | No |
| T019 | Unit test: whitespace | WP03 | P0 | [P] |
| T020 | Unit test: flag order | WP03 | P0 | [P] |
| T021 | Unit test: flag consolidation | WP03 | P0 | [P] |
| T022 | Unit test: exact match | WP03 | P0 | [P] |
| T023 | Import SafetyValidator | WP04 | P0 | [P] |
| T024 | Create validate_safety() | WP04 | P0 | [P] |
| T025 | Implement is_posix_compliant() | WP04 | P0 | [P] |
| T026 | Bash pattern detection | WP04 | P0 | [P] |
| T027 | Zsh pattern detection | WP04 | P0 | [P] |
| T028 | Unit test: safety rm -rf / | WP04 | P0 | [P] |
| T029 | Unit test: safety ls -la | WP04 | P0 | [P] |
| T030 | Unit test: POSIX [ -f ] | WP04 | P0 | [P] |
| T031 | Unit test: bash [[ -f ]] | WP04 | P0 | [P] |
| T032 | Unit test: brace expansion | WP04 | P0 | [P] |
| T033 | Define run_evaluation() | WP05 | P1 | No |
| T034 | Backend initialization | WP05 | P1 | No |
| T035 | Test case execution loop | WP05 | P1 | No |
| T036 | Backend integration | WP05 | P1 | No |
| T037 | Call validators | WP05 | P1 | No |
| T038 | Collect results | WP05 | P1 | No |
| T039 | Handle timeouts | WP05 | P1 | No |
| T040 | Handle malformed responses | WP05 | P1 | No |
| T041 | Integration test: single case | WP05 | P1 | [P] |
| T042 | Integration test: timeout | WP05 | P1 | [P] |
| T043 | Define EvaluationResult | WP06 | P1 | No |
| T044 | Define CategoryResult/FailedCase | WP06 | P1 | No |
| T045 | Define FailureReason enum | WP06 | P1 | No |
| T046 | Implement calculate_csr() | WP06 | P1 | [P] |
| T047 | Implement calculate_safety_accuracy() | WP06 | P1 | [P] |
| T048 | Implement calculate_posix_compliance_rate() | WP06 | P1 | [P] |
| T049 | Per-category breakdown | WP06 | P1 | No |
| T050 | Collect failed_cases | WP06 | P1 | No |
| T051 | Unit test: CSR calculation | WP06 | P1 | [P] |
| T052 | Unit test: safety accuracy | WP06 | P1 | [P] |
| T053 | Unit test: per-category | WP06 | P1 | [P] |
| T054 | Add Serialize derives | WP07 | P1 | No |
| T055 | Implement output_json() | WP07 | P1 | [P] |
| T056 | Implement output_console() | WP07 | P1 | [P] |
| T057 | CSR threshold indicators | WP07 | P1 | [P] |
| T058 | Format failed cases | WP07 | P1 | [P] |
| T059 | Unit test: JSON serialization | WP07 | P1 | [P] |
| T060 | Unit test: console output | WP07 | P1 | [P] |
| T061 | Validate JSON schema | WP07 | P1 | [P] |
| T062 | Create mod.rs test entry | WP08 | P1 | No |
| T063 | Implement test_run_evaluation() | WP08 | P1 | No |
| T064 | Load test dataset | WP08 | P1 | No |
| T065 | Run full harness | WP08 | P1 | No |
| T066 | Assert CSR baseline | WP08 | P1 | No |
| T067 | Assert safety accuracy | WP08 | P1 | No |
| T068 | Assert POSIX compliance | WP08 | P1 | No |
| T069 | GitHub Actions workflow | WP08 | P1 | [P] |
| T070 | Configure CI failure threshold | WP08 | P1 | [P] |
| T071 | Add 20 correctness examples | WP09 | P1 | [P] |
| T072 | Add 10 safety examples | WP09 | P1 | [P] |
| T073 | Add 10 POSIX examples | WP09 | P1 | [P] |
| T074 | Add 10 edge case examples | WP09 | P1 | [P] |
| T075 | Document rationale | WP09 | P1 | No |
| T076 | Validate parsing | WP09 | P1 | No |
| T077 | Verify CSR baseline | WP09 | P1 | No |
| T078 | Review failed cases | WP09 | P1 | No |
| T079 | vLLM backend integration | WP10 | P2 | [P] |
| T080 | Ollama backend integration | WP10 | P2 | [P] |
| T081 | Backend selector logic | WP10 | P2 | No |
| T082 | Create run_consistency_test() | WP10 | P2 | No |
| T083 | Run across backends | WP10 | P2 | No |
| T084 | Calculate similarity score | WP10 | P2 | No |
| T085 | Report divergence | WP10 | P2 | No |
| T086 | Handle unavailable backends | WP10 | P2 | No |
| T087 | Integration test: consistency | WP10 | P2 | [P] |
| T088 | Add consistency metrics | WP10 | P2 | No |

**Total Subtasks**: 88 (78 MVP, 10 P2)
**Total Work Packages**: 10 (9 MVP, 1 P2)
