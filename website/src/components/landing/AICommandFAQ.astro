---
/**
 * AI Command Safety FAQ - Address developer skepticism about AI tools
 * Based on real concerns from community discussions
 */

const concerns = [
  {
    question: "I heard AI coding tools deleted someone's home directory. How is Caro different?",
    answer: "You're right‚Äîit happened with both Claude Code and Gemini CLI in 2025. The tools had safety flags but still ran destructive commands. Caro's safety is pattern-based, not permission-based. We block destructive patterns at the command level. Flags can be bypassed. Pattern matching can't.",
    icon: "üí•"
  },
  {
    question: "What about AI hallucinations? LLMs can make up file paths and commands.",
    answer: "Exactly‚Äîand that's why Caro doesn't trust the source. Whether a command comes from you, an AI, or a hallucinating LLM, Caro validates the command itself. If an AI hallucinates 'rm -rf /nonexistent/but/dangerous/path', the pattern is still blocked. Deterministic validation beats probabilistic generation.",
    icon: "üé≤"
  },
  {
    question: "How should I deploy Caro for AI agents?",
    answer: "Defense in depth: (1) Run as unprivileged user without sudo, (2) Sandbox to specific directories, (3) Use container isolation, (4) Let Caro validate commands. Each layer catches what others miss. See our Best Practices section for detailed setup.",
    icon: "üê≥"
  },
  {
    question: "Wait, Caro runs locally. How does it stay updated with new dangerous patterns?",
    answer: "Caro's safety patterns are baked into the binary‚Äîno network needed. When you update Caro (cargo install caro --force), you get the latest patterns. The core dangerous commands (rm -rf /, fork bombs, disk wipers) don't change. We also accept pattern contributions via GitHub.",
    icon: "üîÑ"
  },
  {
    question: "Will this slow down my incident response?",
    answer: "No. Caro adds <100ms to command generation. The safety check is instant (pattern matching, not AI inference). In a real incident, that's 100ms that might save you from making things 10x worse. The validation is synchronous‚Äîyou see the warning immediately.",
    icon: "‚ö°"
  },
  {
    question: "Can I use Caro in enterprise environments with multiple user accounts?",
    answer: "Yes. Caro is designed for teams running hundreds of developer accounts. Each user gets local validation with no shared state. No cloud dependencies means no data leaks between accounts. Deploy via your package manager or container registry.",
    icon: "üè¢"
  },
  {
    question: "How does it know my specific system setup (BSD vs GNU, etc.)?",
    answer: "Caro detects your OS and shell at runtime. On macOS, it knows you're using BSD tools. On Linux, it adjusts for GNU syntax. It reads your $SHELL and adjusts accordingly. No configuration needed‚Äîit just works.",
    icon: "üñ•Ô∏è"
  },
  {
    question: "What if I actually NEED to run a dangerous command?",
    answer: "Caro warns, it doesn't jail. When you see a warning, you can still proceed‚Äîwe just make sure you're doing it intentionally. For truly destructive commands (rm -rf /), you'll need to confirm. This is your seatbelt, not a straitjacket.",
    icon: "üîì"
  },
  {
    question: "Is this just another AI wrapper that sends my commands to the cloud?",
    answer: "No. Caro runs 100% locally. Your commands, file paths, server names, and directory structures never leave your machine. The inference happens on your hardware. We collect minimal, anonymous usage metrics to improve the product‚Äîsee our telemetry page for details. Check the source code‚Äîit's AGPL-3.0 licensed.",
    icon: "üîí"
  },
  {
    question: "Why should I trust AI-generated shell commands at all?",
    answer: "You shouldn't trust them blindly‚Äîthat's the point. Caro generates commands AND validates them before you run them. It's not 'trust the AI'‚Äîit's 'trust the pattern-based safety layer that catches what the AI might get wrong.' The validation is deterministic, not probabilistic.",
    icon: "üéØ"
  },
  {
    question: "Aren't LLMs trained to be agreeable? Doesn't that make them dangerous?",
    answer: "Yes‚Äîthis is called LLM sycophancy. AI tools are trained to agree with users and appear confident, even when they're wrong. Gemini told a user they were 'overqualified and underpaid'‚Äîcompletely fabricated career advice. In shell commands, this means the AI will confidently generate commands that look right but are subtly destructive. Caro doesn't care about confidence. It validates the actual command.",
    icon: "üé≠"
  },
  {
    question: "Who's responsible when an AI command goes wrong? The AI can't be held accountable.",
    answer: "Exactly the problem. The machine cannot be held responsible, but the decision is yours. That's the 'decision responsibility gap'‚Äîyou're accountable for commands an AI suggested but can't fully verify. Caro bridges this gap: you make informed decisions with explicit warnings about dangerous patterns. No more dice-roll decision making.",
    icon: "‚öñÔ∏è"
  }
];
---

<section id="faq" class="faq-section">
  <div class="container">
    <h2>Common Concerns</h2>
    <p class="section-subtitle">Real questions from skeptical engineers (we get it)</p>

    <div class="faq-grid">
      {concerns.map((item) => (
        <details class="faq-item">
          <summary class="faq-question">
            <span class="faq-icon">{item.icon}</span>
            <span class="faq-text">{item.question}</span>
            <span class="faq-toggle">+</span>
          </summary>
          <div class="faq-answer">
            <p>{item.answer}</p>
          </div>
        </details>
      ))}
    </div>

    <div class="faq-cta">
      <p>Still skeptical? Good‚Äîyou should be.</p>
      <a href="https://github.com/wildcard/caro" class="cta-link" target="_blank" rel="noopener noreferrer">
        Read the source code &rarr;
      </a>
    </div>
  </div>
</section>

<style>
  .faq-section {
    padding: 80px 20px;
    background: var(--color-bg-secondary);
  }

  .container {
    max-width: 800px;
    margin: 0 auto;
  }

  h2 {
    font-size: 36px;
    text-align: center;
    margin-bottom: 12px;
    color: var(--color-text);
  }

  .section-subtitle {
    text-align: center;
    color: var(--color-text-secondary);
    font-size: 18px;
    margin-bottom: 50px;
  }

  .faq-grid {
    display: flex;
    flex-direction: column;
    gap: 16px;
  }

  .faq-item {
    background: var(--color-bg);
    border: 1px solid var(--color-border);
    border-radius: 12px;
    overflow: hidden;
    transition: border-color 0.2s;
  }

  .faq-item:hover {
    border-color: rgba(255, 140, 66, 0.3);
  }

  .faq-item[open] {
    border-color: #ff8c42;
  }

  .faq-question {
    display: flex;
    align-items: center;
    gap: 14px;
    padding: 20px 24px;
    cursor: pointer;
    list-style: none;
    font-weight: 500;
    color: var(--color-text);
  }

  .faq-question::-webkit-details-marker {
    display: none;
  }

  .faq-icon {
    font-size: 24px;
    flex-shrink: 0;
  }

  .faq-text {
    flex-grow: 1;
    font-size: 16px;
    line-height: 1.5;
  }

  .faq-toggle {
    flex-shrink: 0;
    font-size: 24px;
    color: var(--color-text-secondary);
    transition: transform 0.2s;
  }

  .faq-item[open] .faq-toggle {
    transform: rotate(45deg);
  }

  .faq-answer {
    padding: 0 24px 24px 62px;
  }

  .faq-answer p {
    font-size: 15px;
    line-height: 1.7;
    color: var(--color-text-secondary);
    margin: 0;
  }

  .faq-cta {
    text-align: center;
    margin-top: 50px;
    padding: 32px;
    background: linear-gradient(135deg, rgba(255, 140, 66, 0.08) 0%, rgba(255, 107, 53, 0.04) 100%);
    border: 1px solid rgba(255, 140, 66, 0.2);
    border-radius: 12px;
  }

  .faq-cta p {
    font-size: 16px;
    color: var(--color-text);
    margin-bottom: 12px;
  }

  .cta-link {
    color: #ff8c42;
    font-weight: 600;
    text-decoration: none;
    font-size: 16px;
  }

  .cta-link:hover {
    text-decoration: underline;
  }

  @media (max-width: 768px) {
    h2 {
      font-size: 28px;
    }

    .faq-question {
      padding: 16px 18px;
    }

    .faq-answer {
      padding: 0 18px 20px 18px;
    }

    .faq-icon {
      display: none;
    }
  }
</style>
